{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "In this project, the goal is to write a software pipeline to identify the lane boundaries in a video from a front-facing camera on a car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Camera Calibration\n",
    "\n",
    "Determine the camera parameters using a checkerboard pattern for reference.\n",
    "This step must come up with a matrix transform that accounts for distortion.\n",
    "\n",
    "*You need to set your chessboard size to 9x6 for the project!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Camera calibration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal_dir = './camera_cal/'\n",
    "nx = 9\n",
    "ny = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Find the corners of the checkerboard and unwarp the image\n",
    "\n",
    "* This function comes from the Camera Calibration -> Undistort and Transform lesson (18)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corners_unwarp(img, nx, ny):\n",
    "    checkerboard_size = 100\n",
    "    # 0) run the opencv camera claibration routine\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[::-1], None, None)\n",
    "    # 1) Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # 2) Convert to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # 3) Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    # 4) If corners found: \n",
    "    if ret:\n",
    "        # a) draw corners\n",
    "        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        # b) define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "            #Note: you could pick any four of the detected corners \n",
    "            # as long as those four corners define a rectangle\n",
    "            #One especially smart way to do this would be to use four well-chosen\n",
    "            # corners that were automatically detected during the undistortion steps\n",
    "            #We recommend using the automatic detection of corners in your code\n",
    "        src = np.vstack([corners[0], corners[nx-1], corners[-nx], corners[-1]])\n",
    "        # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "        dst = np.float32([[checkerboard_size,checkerboard_size],\n",
    "                          [img.shape[1]-checkerboard_size,checkerboard_size],\n",
    "                          [checkerboard_size,img.shape[0]-checkerboard_size],\n",
    "                          [img.shape[1]-checkerboard_size,img.shape[0]-checkerboard_size]])\n",
    "        # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        #M = cv2.getPerspectiveTransform(dst,src)\n",
    "        # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Perform the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in glob.glob(camera_cal_dir+'calibration*.jpg'):\n",
    "    img = cv2.imread(fname)\n",
    "    top_down, perspective_M = corners_unwarp(img, nx, ny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Radius of Curvature\n",
    "\n",
    "*Radius of curvature should be on the order of 1 km for the videos in this project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sliding window search using convolution\n",
    "\n",
    "* This code comes from the Advanced Computer Vision -> Another Sliding Window Search module (6)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/4):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/4):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,image.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Measure the radius of curvature\n",
    "\n",
    "Find the radius of curvature in metric units, not pixels.\n",
    "\n",
    "'This code comes from the Advanced Computer Vision -> Measuring Curvature II module (8)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_of_curvature(fit, y):\n",
    "    return ((1 + (2*fit[0]*y + fit[1])**2)**(1.5)) / np.absolute(2*fit[0])\n",
    "\n",
    "def measure_curvature_real(ploty, left_fit_cr, right_fit_cr):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)*ym_per_pix\n",
    "    \n",
    "    return radius_of_curvature(fit=left_cr_fit, y=y_eval), radius_of_curvature(fit=right_cr_fit, y=y_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Line Class\n",
    "\n",
    "* The code for the Line Class was given in the Tips and Tricks for this project. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Lane Boundaries Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Drawing\n",
    "\n",
    "* The code for drawing was given in the Tips and Tricks for this project. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
